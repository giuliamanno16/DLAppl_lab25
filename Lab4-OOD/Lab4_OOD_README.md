# Lab 4 – Out-of-Distribution Detection & Adversarial Robustness

## Descrizione

L’ultimo laboratorio esplora metodi per rilevare dati fuori distribuzione e difendersi da input adversariali. Si utilizzano metriche come Maximum Softmax Probability e logit, si testa l’uso di autoencoder per OOD detection e si sperimentano attacchi FGSM sia mirati che non. Si introduce anche la calibrazione (ECE) e tecniche avanzate come ensembling e MC Dropout.

## Esecuzione

Puoi eseguire il notebook:

- [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/giuliamanno16/DLAppl_lab25/blob/main/Lab4_OOD_2025.ipynb)
- [Visualizza su GitHub ](https://github.com/giuliamanno16/DLAppl_lab25/blob/main/Lab4_OOD_2025.ipynb)

### Requisiti

- Python ≥ 3.8
- I pacchetti richiesti sono specificati in `requirements.txt`. Installa tutto con:

```bash
pip install -r requirements.txt
```

## Autore

Giulia Manno – Deep Learning Applications (A.A. 2024/2025)
